{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Zadanie 2.\n",
    "\n",
    "Przygotuj chmurę słów (lub wykres kolumnowy dla 50 najczęściej używanych słów) w oparciu o *bag-of-words*. Dla pozyskanych przez Ciebie dokumentów (w języku angielskim). Korpus ma odzwierciedlać pewną dychotomię - konflikt, dyskusję dwóch stron pewnego zjawiska np: zmian klimatycznych, lockdownu, ulubionego sportu (rugby vs. piłka nożna). Mogą to być: teksty tweetów na wybrane tematy (min 1000 tweetów dla każdej strony); dwóch grup artykułów (po 3-5 dla każdej strony, każdy ponad 2000 wyrazów); wypowiedzi dwóch ekspertów czy polityków (po 3-5 dla każdej strony, każdy ponad 2000 wyrazów).\n",
    "\n",
    "Analizę wykonaj w dwóch wersjach:\n",
    "\n",
    "1. dwa teksty traktowane są osobno - jako dwa osobne korpusy, przygotuj dwie wizualizacje dla każdej strony osobno.\n",
    "2. dwa teksty traktowane są jako jeden i wykonaj wizualizację prezentującą:\n",
    "\n",
    "    - termów charakterystycznych dla każdej ze stron (termy pojawiające się w wypowiedziach jednej strony ale nie pojawiające się w wypowiedziach drugiej strony),\n",
    "    - termów wspólnych dla dwóch stron (termy pojawiające się w wypowiedziach jednej i drugiej strony jednocześnie).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import nest_asyncio\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('SnowballStemmer')\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = twint.Config()\n",
    "# c.Search = '#verstappen'\n",
    "# c.Limit = 5\n",
    "# twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja pobierająca dane za pomocą biblioteki twint\n",
    "def get_data(query, limit):\n",
    "    c = twint.Config()\n",
    "    c.Search = query\n",
    "    c.Lang = 'en'\n",
    "    c.Limit = limit\n",
    "    c.Pandas = True\n",
    "    twint.run.Search(c)\n",
    "    tweets = twint.storage.panda.Tweets_df\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja oczyszczająca tweety\n",
    "def cleaned_tweets(text):\n",
    "    # normalizacja tekstu\n",
    "    temp = re.sub(\"\\s{2,}\", \" \", text)\n",
    "    temp = re.sub(\"(\\r\\n|\\r|\\n)\", \" \", temp) \n",
    "    temp = temp.lower() \n",
    "    temp = re.sub(\"rt\", \"\", temp) \n",
    "    temp = re.sub(\"&amp\", \"\", temp) \n",
    "    temp = re.sub(\"#[a-z,A-Z]*\", \"\", temp)\n",
    "    temp = re.sub(\"@\\w+\", \"\", temp) \n",
    "    temp = re.sub(\"(f|ht)(tp)([^ ]*)\", \"\", temp) \n",
    "    temp = re.sub(\"http(s?)([^ ]*)\", \"\", temp)\n",
    "    temp = re.sub(\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \" \", temp) \n",
    "    temp = re.sub(\"\\d\", \"\", temp) \n",
    "    temp = re.sub(\"\\s{2,}\", \" \", temp) \n",
    "    temp = temp.strip()\n",
    "    \n",
    "    # usuwanie duplikatów ze zbioru\n",
    "    words_set = set(temp.split())\n",
    "    words_list = list(words_set)\n",
    "    \n",
    "    # tokenizacja\n",
    "    tokens = nltk.word_tokenize(\" \".join(words_list))\n",
    "    \n",
    "    # tworzenie listy stop słów\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens if not token in stop_words]\n",
    "    \n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja funkcji generującej chmurę słów\n",
    "def generate_wordcloud(data):\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words=50, contour_width=3, contour_color='steelblue')\n",
    "    wordcloud.generate(data)\n",
    "    plt.figure(figsize = (8, 8), facecolor = 'k', edgecolor = 'k')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie tweetów na temat Brexitu\n",
    "brexit_tweets = get_data(\"Brexit\", 1000)\n",
    "# pobranie tweetów na temat pozostania w UE\n",
    "remain_tweets = get_data(\"Remain\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oczyszczenie tweetów na temat Brexit\n",
    "brexit_cleaned_tweets = [cleaned_tweets(tweet) for tweet in brexit_tweets[\"tweet\"]]\n",
    "# oczyszczenie tweetów na temat Remain\n",
    "remain_cleaned_tweets = [cleaned_tweets(tweet) for tweet in remain_tweets[\"tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stworzenie jednego tekstu na temat Brexit\n",
    "brexit_text = \" \".join([\" \".join(tweet) for tweet in brexit_cleaned_tweets])\n",
    "# stworzenie jednego tekstu na temat Remain\n",
    "remain_text = \" \".join([\" \".join(tweet) for tweet in remain_cleaned_tweets])\n",
    "\n",
    "# generowanie chmur słów\n",
    "generate_wordcloud(brexit_text) # chmura słów dla Brexit\n",
    "generate_wordcloud(remain_text) # chmura słów dla Remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funkcja umożliwiająca liczenie słów\n",
    "def count_words(text):\n",
    "    word_counts = {}\n",
    "    for tweet in text:\n",
    "        for word in tweet:\n",
    "            if word not in word_counts:\n",
    "                word_counts[word] = 1\n",
    "            else:\n",
    "                word_counts[word] += 1\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policzenie słów dla Brexit\n",
    "brexit_word_counts = count_words(brexit_cleaned_tweets)\n",
    "# policzenie słów dla Remain\n",
    "remain_word_counts = count_words(remain_cleaned_tweets)\n",
    "\n",
    "# wyświetlenie 50 najczęściej używanych słów dla Brexit\n",
    "brexit_top_50 = pd.DataFrame(list(brexit_word_counts.items()),columns = ['Word','Count']).sort_values(by=['Count'], ascending=False).head(50)\n",
    "print(brexit_top_50)\n",
    "\n",
    "# wyświetlenie 50 najczęściej używanych słów dla Remain\n",
    "remain_top_50 = pd.DataFrame(list(remain_word_counts.items()),columns = ['Word','Count']).sort_values(by=['Count'], ascending=False).head(50)\n",
    "print(remain_top_50)\n",
    "\n",
    "# wykres kolumnowy dla 50 najczęściej używanych słów dla Brexit\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.bar(brexit_top_50[\"Word\"], brexit_top_50[\"Count\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# wykres kolumnowy dla 50 najczęściej używanych słów dla Remain\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.bar(remain_top_50[\"Word\"], remain_top_50[\"Count\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
